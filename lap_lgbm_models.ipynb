{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aade96ff",
   "metadata": {
    "papermill": {
     "duration": 0.01063,
     "end_time": "2024-10-31T09:02:12.026403",
     "exception": false,
     "start_time": "2024-10-31T09:02:12.015773",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Import Libraries / Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3b43880",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:12.048493Z",
     "iopub.status.busy": "2024-10-31T09:02:12.047949Z",
     "iopub.status.idle": "2024-10-31T09:02:15.195878Z",
     "shell.execute_reply": "2024-10-31T09:02:15.194660Z"
    },
    "papermill": {
     "duration": 3.162284,
     "end_time": "2024-10-31T09:02:15.198690",
     "exception": false,
     "start_time": "2024-10-31T09:02:12.036406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import lightgbm as lgb\n",
    "from lightgbm import early_stopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "random_state = 68"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c704d7",
   "metadata": {},
   "source": [
    "`cat_enc`: Encodes categorical variables using either One Hot Encoding or Ordinal Encoding.\n",
    "\n",
    "`lir_impute`: Uses Linear Regression to impute missing values.\n",
    "\n",
    "`create_var`: Creates new features that are hand-made.\n",
    "\n",
    "`feature_engineering`: Combines above 3 functions to perform feature engineering on dataset.\n",
    "\n",
    "\n",
    "Creating a seperate function for feature engineering is important as this feature engineering includes imputation of data, and therefore, it should be done after cv is splitted to reduce contamination of cv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8542e8a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:17.369347Z",
     "iopub.status.busy": "2024-10-31T09:02:17.368846Z",
     "iopub.status.idle": "2024-10-31T09:02:17.404471Z",
     "shell.execute_reply": "2024-10-31T09:02:17.403144Z"
    },
    "papermill": {
     "duration": 0.050297,
     "end_time": "2024-10-31T09:02:17.407466",
     "exception": false,
     "start_time": "2024-10-31T09:02:17.357169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cat_enc(df, ohe, ordi, cats):\n",
    "    other_var = [\"person_age\", \"person_income\", \"person_emp_length\", \"loan_amnt\", \"loan_int_rate\", \"loan_percent_income\", \n",
    "                 \"cb_person_cred_hist_length\", \"Type\", \"loan_status\"]\n",
    "    df_cat1 = pd.DataFrame(ohe.transform(df[cats[0]]), columns = [x for xs in ohe.categories_ for x in xs]).reset_index(drop=True)\n",
    "    df_cat2 = pd.DataFrame(ordi.transform(df[cats[1]]), columns = cats[1]).reset_index(drop=True)\n",
    "    df_cat = pd.concat([df_cat1, df_cat2], axis=1)\n",
    "    df_enc = pd.concat([df[other_var].reset_index(drop=True),df_cat], axis=1)\n",
    "    return df_enc\n",
    "\n",
    "def lir_impute(lr, df_nmv, df_mv, features):\n",
    "    df_mv['loan_int_rate'] = lr.predict(df_mv[features])\n",
    "    return pd.concat([df_nmv, df_mv]).reset_index(drop=True)\n",
    "\n",
    "def create_var(data, aita, aite):\n",
    "    df = data.copy()\n",
    "    df['loan_int_rate'] = df['loan_int_rate']/100\n",
    "    df['loan_int_rate_month'] = (1 + df['loan_int_rate'])**(1/12) - 1\n",
    "    k =  1 + df['loan_int_rate_month']\n",
    "    P = df['person_income']*df['loan_percent_income']/12\n",
    "    L = df['loan_amnt']\n",
    "    tmp = (np.log(P/(P-L*(k-1)))/np.log(k)).replace([np.inf,-np.inf], np.nan)\n",
    "    df['est_payback_time_in_month'] = tmp.fillna(-999)\n",
    "    df['avg_income_by_age'] = [aita[x] if x in aita.index else aita[aita.index[abs(aita.index - x).argmin()]] for x in df[\"person_age\"]]\n",
    "    df['avg_income_by_emp'] = [aite[x] if x in aite.index else aite[aite.index[abs(aite.index - x).argmin()]] for x in df[\"person_age\"]]\n",
    "    df['income_diff_avg_age'] = df['person_income'] - df['avg_income_by_age']\n",
    "    df['income_diff_avg_emp'] = df['person_income'] - df['avg_income_by_emp']\n",
    "    df['risk_flag'] = ((df['Y'] == 1) & (df['loan_grade'].replace([\"D\",\"E\",\"F\",\"G\"], \"low\") == \"low\")).astype(\"int\")\n",
    "    return df\n",
    "    \n",
    "def feature_engineering(data, data_cv, impute=False, min_max = False):\n",
    "    df = data.copy()\n",
    "    df_cv = data_cv.copy()\n",
    "    \n",
    "    # Step 1: Encoding Categorical Variables\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    ordi = OrdinalEncoder(handle_unknown='error')\n",
    "    cats = [['person_home_ownership','loan_intent','cb_person_default_on_file'], ['loan_grade']]\n",
    "    ohe.fit(df[cats[0]])\n",
    "    ordi.fit(df[cats[1]])\n",
    "    df_enc = cat_enc(df, ohe, ordi, cats)\n",
    "    df_cv_enc = cat_enc(df_cv, ohe, ordi, cats)\n",
    "    \n",
    "    if impute:\n",
    "        # Step 2.1: Imputing Missing Values - `loan_int_rate`\n",
    "        df_mv = df_enc[(df_enc.isna()[\"loan_int_rate\"])]\n",
    "        df_nmv = df_enc[~(df_enc.isna()[\"loan_int_rate\"])]\n",
    "        df_cv_mv = df_cv_enc[(df_cv_enc.isna()[\"loan_int_rate\"])]\n",
    "        df_cv_nmv = df_cv_enc[~(df_cv_enc.isna()[\"loan_int_rate\"])]\n",
    "        features_infer = df_nmv.columns[~((df_nmv.columns == 'person_emp_length') | (df_nmv.columns == 'loan_int_rate') | (df_nmv.columns == 'loan_status') | (df_nmv.columns == 'Type'))]\n",
    "        df_nmv_train, df_nmv_infer = df_nmv[features_infer], df_nmv['loan_int_rate']\n",
    "        lr = LinearRegression().fit(df_nmv_train, df_nmv_infer)\n",
    "        df_enc = lir_impute(lr, df_nmv, df_mv, features_infer)\n",
    "        df_cv_enc = lir_impute(lr, df_cv_nmv, df_cv_mv, features_infer)\n",
    "        \n",
    "        # Step 2.2: Imputing Missing Values - `person_emp_length`\n",
    "        df_mv = df_enc[(df_enc.isna()[\"person_emp_length\"])]\n",
    "        df_nmv = df_enc[~(df_enc.isna()[\"person_emp_length\"])]\n",
    "        diff_scores = [2.205876158220027e-52, 2.8034878798264012e-36, 7.216755273392921e-12]\n",
    "        pel_u = []\n",
    "        for col in ['person_income', 'loan_amnt', 'loan_percent_income']:\n",
    "            mean = np.mean(df_mv[col])\n",
    "            std = np.std(df_mv[col])\n",
    "            d = df_nmv[\"person_emp_length\"][(df_nmv[col] > mean-3*std) & (df_nmv[col] < mean+3*std)]\n",
    "            pel_u.append(np.mean(d))\n",
    "        pel_weights = np.log(1/np.array(diff_scores)) # Stronger weights for variables with higher confidence + Softened\n",
    "        pel_weights = pel_weights / np.sum(pel_weights)\n",
    "        pel_mean = np.sum(pel_u*pel_weights)\n",
    "        df_enc['person_emp_length'] = df_enc['person_emp_length'].fillna(pel_mean)\n",
    "        df_cv_enc['person_emp_length'] = df_cv_enc['person_emp_length'].fillna(pel_mean)\n",
    "    \n",
    "    # Step 3: Creating New Variables\n",
    "    aita = df_enc.groupby(\"person_age\")[\"person_income\"].mean()\n",
    "    aite = df_enc.groupby(\"person_emp_length\")[\"person_income\"].mean()\n",
    "    df_fe = create_var(df_enc, aita, aite)\n",
    "    df_cv_fe = create_var(df_cv_enc, aita, aite)\n",
    "    \n",
    "    # Step 4: Scale Normalizing with Scaler\n",
    "    train_cols = df_fe.columns[[x not in ['loan_status'] for x in df_fe.columns]]\n",
    "    Xdf_fe = df_fe[train_cols]\n",
    "    ydf_fe = df_fe['loan_status']\n",
    "    Xdf_cv_fe = df_cv_fe[train_cols]\n",
    "    ydf_cv_fe = df_cv_fe['loan_status']\n",
    "    if min_max:\n",
    "        scaler = MinMaxScaler().fit(Xdf_fe)\n",
    "    else:\n",
    "        scaler = StandardScaler().fit(Xdf_fe)\n",
    "    cols = Xdf_fe.columns\n",
    "    Xdf_fe = pd.DataFrame(scaler.transform(Xdf_fe), columns = cols)\n",
    "    Xdf_cv_fe = pd.DataFrame(scaler.transform(Xdf_cv_fe), columns = cols)\n",
    "    \n",
    "    return [Xdf_fe, ydf_fe, Xdf_cv_fe, ydf_cv_fe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b7d201",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this path to the directory of your data file.\n",
    "path = \"/kaggle/input/loan-approval-prediction-pre/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6b3bde",
   "metadata": {
    "papermill": {
     "duration": 0.009731,
     "end_time": "2024-10-31T09:02:17.427129",
     "exception": false,
     "start_time": "2024-10-31T09:02:17.417398",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Models - LGBM\n",
    "Note: For each model trained, the best set of hyperparameters and the best 5 cv iteration rounds will be kept to later create five models, which will be used in aggregate to make final prediction. (For generalization.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b705bd",
   "metadata": {
    "papermill": {
     "duration": 0.009423,
     "end_time": "2024-10-31T09:02:17.446421",
     "exception": false,
     "start_time": "2024-10-31T09:02:17.436998",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. lbm11\n",
    "* Data: Train (Unmerged)\n",
    "* Model: LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a69d622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:17.467813Z",
     "iopub.status.busy": "2024-10-31T09:02:17.467373Z",
     "iopub.status.idle": "2024-10-31T09:02:17.705589Z",
     "shell.execute_reply": "2024-10-31T09:02:17.704111Z"
    },
    "papermill": {
     "duration": 0.252621,
     "end_time": "2024-10-31T09:02:17.708764",
     "exception": false,
     "start_time": "2024-10-31T09:02:17.456143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(path + \"/trains.csv\")\n",
    "y = X['loan_status']\n",
    "opt_lgbm11 = False\n",
    "lgbm11_exist = True\n",
    "\n",
    "if lgbm11_exist: # This is for kaggle (hyperparameter tuning had to be broken down as there weren't enough computation resources)\n",
    "    os.system('cp /kaggle/input/lgbmoptuna/lgbm11.db /kaggle/working/lgbm11.db')\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_categorical('num_leaves',[2,4,8,16,32,64,128,256,512,1024]),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5,1,step=0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 10000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001,1,log=True),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 5, 100),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 1, 50),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 70),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n",
    "        'verbose': trial.suggest_categorical('verbose', [-1])\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **params)\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "    cv_splits = cv.split(X, y)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        Xtrain, Xval = X.loc[train_idx], X.loc[val_idx] # y will be separated later, as feature engineering mix the indices greatly.\n",
    "        Xtrain, ytrain, Xval, yval = feature_engineering(Xtrain, Xval)\n",
    "        callbacks = [early_stopping(stopping_rounds=200, verbose=0), lgb.log_evaluation(period=0)]\n",
    "        model.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], callbacks=callbacks, eval_metric = \"auc\")\n",
    "        pred = model.predict_proba(Xval)[:,1]\n",
    "        score = roc_auc_score(yval, pred)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "sqlite_db = \"sqlite:///lgbm11.db\"\n",
    "study_name = \"unmerged_ss\"\n",
    "if opt_lgbm11:\n",
    "    study = optuna.create_study(storage = sqlite_db, study_name = study_name, \n",
    "                               sampler = TPESampler(n_startup_trials=35, multivariate=True, seed=random_state),\n",
    "                               direction=\"maximize\", load_if_exists=True)\n",
    "    study.optimize(objective, n_trials = 100, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ea2eec7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:17.731372Z",
     "iopub.status.busy": "2024-10-31T09:02:17.730880Z",
     "iopub.status.idle": "2024-10-31T09:02:19.829285Z",
     "shell.execute_reply": "2024-10-31T09:02:19.827949Z"
    },
    "papermill": {
     "duration": 2.113313,
     "end_time": "2024-10-31T09:02:19.832468",
     "exception": false,
     "start_time": "2024-10-31T09:02:17.719155",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters and Score: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "value               0.958349\n",
       "colsample_bytree         1.0\n",
       "learning_rate       0.035401\n",
       "min_child_weight           5\n",
       "n_estimators            6900\n",
       "num_leaves                 8\n",
       "reg_alpha                  1\n",
       "reg_lambda                 6\n",
       "subsample                0.8\n",
       "verbose                   -1\n",
       "state               COMPLETE\n",
       "Name: 96, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Iterations: \n",
      "[1808, 2284, 1532, 1567, 1811]\n"
     ]
    }
   ],
   "source": [
    "# Analyze Store (Best) Study Outcome\n",
    "if opt_lgbm11:\n",
    "    lgbm11_out = study.trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm11_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm11_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm11_out = lgbm11_out[focus_col]\n",
    "    display(xgb11_out.head())\n",
    "if lgbm11_exist:\n",
    "    lgbm11_out = optuna.load_study(study_name = study_name, storage=sqlite_db).trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm11_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm11_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm11_out = lgbm11_out[focus_col]\n",
    "    best_param = lgbm11_out.iloc[0,:]\n",
    "    lgbm11_params = {\n",
    "        'num_leaves': best_param[\"num_leaves\"],\n",
    "        'subsample': best_param['subsample'],\n",
    "        'n_estimators': best_param['n_estimators'],\n",
    "        'learning_rate': best_param['learning_rate'],\n",
    "        'reg_lambda': best_param['reg_lambda'],\n",
    "        'reg_alpha': best_param['reg_alpha'],\n",
    "        'min_child_weight': best_param['min_child_weight'],\n",
    "        'colsample_bytree': best_param['colsample_bytree'],\n",
    "        'verbose': best_param['verbose']\n",
    "    }\n",
    "    print(\"Best Parameters and Score: \")\n",
    "    display(best_param)\n",
    "    print(\"Best CV Iterations: \")\n",
    "    lgbm11_iter = [1808, 2284, 1532, 1567, 1811]\n",
    "    print(lgbm11_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5beed1e0",
   "metadata": {
    "papermill": {
     "duration": 0.010042,
     "end_time": "2024-10-31T09:02:19.852939",
     "exception": false,
     "start_time": "2024-10-31T09:02:19.842897",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. lgbm21\n",
    "* Data: Train (Merged / Dropped)\n",
    "* Model: LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48d07d98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:19.876568Z",
     "iopub.status.busy": "2024-10-31T09:02:19.875860Z",
     "iopub.status.idle": "2024-10-31T09:02:20.126532Z",
     "shell.execute_reply": "2024-10-31T09:02:20.125393Z"
    },
    "papermill": {
     "duration": 0.265051,
     "end_time": "2024-10-31T09:02:20.129358",
     "exception": false,
     "start_time": "2024-10-31T09:02:19.864307",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(path + \"/merge_rmvd.csv\")\n",
    "y = X['loan_status']\n",
    "opt_lgbm21 = False\n",
    "lgbm21_exist = True\n",
    "\n",
    "if lgbm21_exist: # This is for kaggle (hyperparameter tuning had to be broken down as there weren't enough computation resources)\n",
    "    os.system('cp /kaggle/input/lgbmoptuna/lgbm21.db /kaggle/working/lgbm21.db')\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_categorical('num_leaves',[2,4,8,16,32,64,128,256,512,1024]),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5,1,step=0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 10000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001,1,log=True),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 5, 100),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 1, 50),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 70),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n",
    "        'verbose': trial.suggest_categorical('verbose', [-1])\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **params)\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "    cv_splits = cv.split(X, y)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        Xtrain, Xval = X.loc[train_idx], X.loc[val_idx] # y will be separated later, as feature engineering mix the indices greatly.\n",
    "        Xtrain, ytrain, Xval, yval = feature_engineering(Xtrain, Xval)\n",
    "        callbacks = [early_stopping(stopping_rounds=200, verbose=0), lgb.log_evaluation(period=0)]\n",
    "        model.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], callbacks=callbacks, eval_metric = \"auc\")\n",
    "        pred = model.predict_proba(Xval)[:,1]\n",
    "        score = roc_auc_score(yval, pred)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "sqlite_db = \"sqlite:///lgbm21.db\"\n",
    "study_name = \"mergervmd_ss\"\n",
    "if opt_lgbm21:\n",
    "    study = optuna.create_study(storage = sqlite_db, study_name = study_name, \n",
    "                               sampler = TPESampler(n_startup_trials=35, multivariate=True, seed=random_state),\n",
    "                               direction=\"maximize\", load_if_exists=True)\n",
    "    study.optimize(objective, n_trials = 100, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d36ea1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.152300Z",
     "iopub.status.busy": "2024-10-31T09:02:20.151860Z",
     "iopub.status.idle": "2024-10-31T09:02:20.329064Z",
     "shell.execute_reply": "2024-10-31T09:02:20.327953Z"
    },
    "papermill": {
     "duration": 0.19172,
     "end_time": "2024-10-31T09:02:20.331735",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.140015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters and Score: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "value               0.960164\n",
       "colsample_bytree         0.6\n",
       "learning_rate       0.070034\n",
       "min_child_weight          31\n",
       "n_estimators            8500\n",
       "num_leaves                16\n",
       "reg_alpha                  1\n",
       "reg_lambda                57\n",
       "subsample                0.9\n",
       "verbose                   -1\n",
       "state               COMPLETE\n",
       "Name: 80, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Iterations: \n",
      "[1645, 1630, 1708, 2023, 1659]\n"
     ]
    }
   ],
   "source": [
    "# Analyze Store (Best) Study Outcome\n",
    "if opt_lgbm21:\n",
    "    lgbm21_out = study.trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm21_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm21_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm21_out = lgbm21_out[focus_col]\n",
    "    display(lgbm21_out.head())\n",
    "if lgbm21_exist:\n",
    "    lgbm21_out = optuna.load_study(study_name = study_name, storage=sqlite_db).trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm21_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm21_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm21_out = lgbm21_out[focus_col]\n",
    "    best_param = lgbm21_out.iloc[0,:]\n",
    "    lgbm21_params = {\n",
    "        'num_leaves': best_param[\"num_leaves\"],\n",
    "        'subsample': best_param['subsample'],\n",
    "        'n_estimators': best_param['n_estimators'],\n",
    "        'learning_rate': best_param['learning_rate'],\n",
    "        'reg_lambda': best_param['reg_lambda'],\n",
    "        'reg_alpha': best_param['reg_alpha'],\n",
    "        'min_child_weight': best_param['min_child_weight'],\n",
    "        'colsample_bytree': best_param['colsample_bytree'],\n",
    "        'verbose': best_param['verbose']\n",
    "    }\n",
    "    print(\"Best Parameters and Score: \")\n",
    "    display(best_param)\n",
    "    print(\"Best CV Iterations: \")\n",
    "    lgbm21_iter = [1645, 1630, 1708, 2023, 1659]\n",
    "    print(lgbm21_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "142499ea",
   "metadata": {
    "papermill": {
     "duration": 0.010706,
     "end_time": "2024-10-31T09:02:20.352910",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.342204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. lgbm31\n",
    "* Data: Train (Merged / Imputed)\n",
    "* LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e36edec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.376101Z",
     "iopub.status.busy": "2024-10-31T09:02:20.375619Z",
     "iopub.status.idle": "2024-10-31T09:02:20.622519Z",
     "shell.execute_reply": "2024-10-31T09:02:20.621316Z"
    },
    "papermill": {
     "duration": 0.262041,
     "end_time": "2024-10-31T09:02:20.625653",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.363612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = pd.read_csv(path + \"/merged.csv\")\n",
    "y = X['loan_status']\n",
    "opt_lgbm31 = False\n",
    "lgbm31_exist = True\n",
    "\n",
    "if lgbm31_exist: # This is for kaggle (hyperparameter tuning had to be broken down as there weren't enough computation resources)\n",
    "    os.system('cp /kaggle/input/lgbmoptuna/lgbm31.db /kaggle/working/lgbm31.db')\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_categorical('num_leaves',[2,4,8,16,32,64,128,256,512,1024]),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5,1,step=0.05),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 10000, step=100),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.001,1,log=True),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 5, 100),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 1, 50),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 70),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1, step=0.1),\n",
    "        'verbose': trial.suggest_categorical('verbose', [-1])\n",
    "    }\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **params)\n",
    "    cv = StratifiedKFold(5, shuffle=True, random_state=random_state)\n",
    "    cv_splits = cv.split(X, y)\n",
    "    scores = []\n",
    "    for train_idx, val_idx in cv_splits:\n",
    "        Xtrain, Xval = X.loc[train_idx], X.loc[val_idx] # y will be separated later, as feature engineering mix the indices greatly.\n",
    "        Xtrain, ytrain, Xval, yval = feature_engineering(Xtrain, Xval)\n",
    "        callbacks = [early_stopping(stopping_rounds=200, verbose=0), lgb.log_evaluation(period=0)]\n",
    "        model.fit(Xtrain, ytrain, eval_set=[(Xval, yval)], callbacks=callbacks, eval_metric = \"auc\")\n",
    "        pred = model.predict_proba(Xval)[:,1]\n",
    "        score = roc_auc_score(yval, pred)\n",
    "        scores.append(score)\n",
    "    return np.mean(scores)\n",
    "sqlite_db = \"sqlite:///lgbm31.db\"\n",
    "study_name = \"merged_ss\"\n",
    "if opt_lgbm31:\n",
    "    study = optuna.create_study(storage = sqlite_db, study_name = study_name, \n",
    "                               sampler = TPESampler(n_startup_trials=35, multivariate=True, seed=random_state),\n",
    "                               direction=\"maximize\", load_if_exists=True)\n",
    "    study.optimize(objective, n_trials = 100, gc_after_trial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0642ac09",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.650006Z",
     "iopub.status.busy": "2024-10-31T09:02:20.649526Z",
     "iopub.status.idle": "2024-10-31T09:02:20.782531Z",
     "shell.execute_reply": "2024-10-31T09:02:20.781074Z"
    },
    "papermill": {
     "duration": 0.148301,
     "end_time": "2024-10-31T09:02:20.785057",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.636756",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters and Score: \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "value                0.95906\n",
       "colsample_bytree         0.9\n",
       "learning_rate       0.013924\n",
       "min_child_weight          13\n",
       "n_estimators            5200\n",
       "num_leaves               512\n",
       "reg_alpha                  3\n",
       "reg_lambda                48\n",
       "subsample               0.65\n",
       "verbose                   -1\n",
       "state               COMPLETE\n",
       "Name: 43, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV Iterations: \n",
      "[2155, 2299, 1789, 1743, 1905]\n"
     ]
    }
   ],
   "source": [
    "# Analyze Store (Best) Study Outcome\n",
    "if opt_lgbm31:\n",
    "    lgbm31_out = study.trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm31_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm31_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm31_out = lgbm31_out[focus_col]\n",
    "    display(lgbm31_out.head())\n",
    "if lgbm31_exist:\n",
    "    lgbm31_out = optuna.load_study(study_name = study_name, storage=sqlite_db).trials_dataframe().sort_values(by=\"value\", ascending=False)\n",
    "    lgbm31_out.columns = [x[7:] if x[:7] == \"params_\" else x for x in lgbm31_out.columns]\n",
    "    focus_col = ['value', 'colsample_bytree', 'learning_rate', 'min_child_weight', 'n_estimators',\n",
    "                 'num_leaves', 'reg_alpha', 'reg_lambda', 'subsample', 'verbose', 'state']\n",
    "    lgbm31_out = lgbm31_out[focus_col]\n",
    "    best_param = lgbm31_out.iloc[0,:]\n",
    "    lgbm31_params = {\n",
    "        'num_leaves': best_param[\"num_leaves\"],\n",
    "        'subsample': best_param['subsample'],\n",
    "        'n_estimators': best_param['n_estimators'],\n",
    "        'learning_rate': best_param['learning_rate'],\n",
    "        'reg_lambda': best_param['reg_lambda'],\n",
    "        'reg_alpha': best_param['reg_alpha'],\n",
    "        'min_child_weight': best_param['min_child_weight'],\n",
    "        'colsample_bytree': best_param['colsample_bytree'],\n",
    "        'verbose': best_param['verbose']\n",
    "    }\n",
    "    print(\"Best Parameters and Score: \")\n",
    "    display(best_param)\n",
    "    print(\"Best CV Iterations: \")\n",
    "    lgbm31_iter = [2155, 2299, 1789, 1743, 1905]\n",
    "    print(lgbm31_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffbf813",
   "metadata": {
    "papermill": {
     "duration": 0.010496,
     "end_time": "2024-10-31T09:02:20.806258",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.795762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# LGBM Models Test Outcome (Individual)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e2c7b20",
   "metadata": {
    "papermill": {
     "duration": 0.010376,
     "end_time": "2024-10-31T09:02:20.827426",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.817050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 0. Importing Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b289ae90",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.851431Z",
     "iopub.status.busy": "2024-10-31T09:02:20.850328Z",
     "iopub.status.idle": "2024-10-31T09:02:20.895655Z",
     "shell.execute_reply": "2024-10-31T09:02:20.894352Z"
    },
    "papermill": {
     "duration": 0.060181,
     "end_time": "2024-10-31T09:02:20.898425",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.838244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_age</th>\n",
       "      <th>person_income</th>\n",
       "      <th>person_home_ownership</th>\n",
       "      <th>person_emp_length</th>\n",
       "      <th>loan_intent</th>\n",
       "      <th>loan_grade</th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>loan_int_rate</th>\n",
       "      <th>loan_percent_income</th>\n",
       "      <th>cb_person_default_on_file</th>\n",
       "      <th>cb_person_cred_hist_length</th>\n",
       "      <th>loan_status</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>45000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>17000</td>\n",
       "      <td>12.99</td>\n",
       "      <td>0.36</td>\n",
       "      <td>Y</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>65000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>3.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>B</td>\n",
       "      <td>5000</td>\n",
       "      <td>11.49</td>\n",
       "      <td>0.08</td>\n",
       "      <td>N</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26</td>\n",
       "      <td>90000</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>9.0</td>\n",
       "      <td>DEBTCONSOLIDATION</td>\n",
       "      <td>A</td>\n",
       "      <td>6500</td>\n",
       "      <td>7.14</td>\n",
       "      <td>0.07</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>67000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>10.0</td>\n",
       "      <td>PERSONAL</td>\n",
       "      <td>B</td>\n",
       "      <td>10000</td>\n",
       "      <td>12.21</td>\n",
       "      <td>0.15</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>60000</td>\n",
       "      <td>RENT</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>C</td>\n",
       "      <td>12500</td>\n",
       "      <td>14.22</td>\n",
       "      <td>0.21</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
       "0          25          45000                  RENT                6.0   \n",
       "1          33          65000                  RENT                3.0   \n",
       "2          26          90000              MORTGAGE                9.0   \n",
       "3          26          67000                  RENT               10.0   \n",
       "4          22          60000                  RENT                6.0   \n",
       "\n",
       "         loan_intent loan_grade  loan_amnt  loan_int_rate  \\\n",
       "0            MEDICAL          C      17000          12.99   \n",
       "1  DEBTCONSOLIDATION          B       5000          11.49   \n",
       "2  DEBTCONSOLIDATION          A       6500           7.14   \n",
       "3           PERSONAL          B      10000          12.21   \n",
       "4            MEDICAL          C      12500          14.22   \n",
       "\n",
       "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \\\n",
       "0                 0.36                         Y                           3   \n",
       "1                 0.08                         N                           5   \n",
       "2                 0.07                         N                           2   \n",
       "3                 0.15                         N                           2   \n",
       "4                 0.21                         Y                           2   \n",
       "\n",
       "   loan_status  Type  \n",
       "0            1     1  \n",
       "1            0     1  \n",
       "2            0     1  \n",
       "3            0     1  \n",
       "4            0     1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv(path + \"cv.csv\")\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89d95fcf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.922774Z",
     "iopub.status.busy": "2024-10-31T09:02:20.922358Z",
     "iopub.status.idle": "2024-10-31T09:02:20.928963Z",
     "shell.execute_reply": "2024-10-31T09:02:20.927810Z"
    },
    "papermill": {
     "duration": 0.021982,
     "end_time": "2024-10-31T09:02:20.931642",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.909660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgbm_pred(models, Xtest):\n",
    "    y_pred = []\n",
    "    for model in models:\n",
    "        y_pred.append(model.predict_proba(Xtest)[:,1])\n",
    "    y_pred = np.array(y_pred).sum(axis=0)/len(models)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b46c72",
   "metadata": {
    "papermill": {
     "duration": 0.010735,
     "end_time": "2024-10-31T09:02:20.953619",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.942884",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. `lgbm11` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0452563b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:02:20.978099Z",
     "iopub.status.busy": "2024-10-31T09:02:20.977668Z",
     "iopub.status.idle": "2024-10-31T09:03:35.965333Z",
     "shell.execute_reply": "2024-10-31T09:03:35.964179Z"
    },
    "papermill": {
     "duration": 75.003306,
     "end_time": "2024-10-31T09:03:35.968148",
     "exception": false,
     "start_time": "2024-10-31T09:02:20.964842",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm11_model = []\n",
    "Xtest = test.copy()\n",
    "Xtrain = pd.read_csv(path + \"/trains.csv\")\n",
    "Xtrain, ytrain, Xtest, ytest = feature_engineering(Xtrain, Xtest)\n",
    "for i in range(5):\n",
    "    lgbm11_params['n_estimators'] = lgbm11_iter[i]\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **lgbm11_params)\n",
    "    callbacks = [lgb.log_evaluation(period=0)]\n",
    "    model.fit(Xtrain, ytrain, callbacks=callbacks, eval_metric = \"auc\")\n",
    "    lgbm11_model.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a198d76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:03:35.992405Z",
     "iopub.status.busy": "2024-10-31T09:03:35.991937Z",
     "iopub.status.idle": "2024-10-31T09:03:39.118566Z",
     "shell.execute_reply": "2024-10-31T09:03:39.116828Z"
    },
    "papermill": {
     "duration": 3.141922,
     "end_time": "2024-10-31T09:03:39.121322",
     "exception": false,
     "start_time": "2024-10-31T09:03:35.979400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC Score: 0.9553367977691114\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(ytest, lgbm_pred(lgbm11_model, Xtest))\n",
    "print(\"Test ROC AUC Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57aed2ff",
   "metadata": {
    "papermill": {
     "duration": 0.010904,
     "end_time": "2024-10-31T09:03:39.143671",
     "exception": false,
     "start_time": "2024-10-31T09:03:39.132767",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. `lgbm21` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4773b37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:03:39.168265Z",
     "iopub.status.busy": "2024-10-31T09:03:39.167790Z",
     "iopub.status.idle": "2024-10-31T09:06:10.108596Z",
     "shell.execute_reply": "2024-10-31T09:06:10.107235Z"
    },
    "papermill": {
     "duration": 150.95673,
     "end_time": "2024-10-31T09:06:10.111831",
     "exception": false,
     "start_time": "2024-10-31T09:03:39.155101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm21_model = []\n",
    "Xtest = test.copy()\n",
    "Xtrain = pd.read_csv(path + \"/merge_rmvd.csv\")\n",
    "Xtrain, ytrain, Xtest, ytest = feature_engineering(Xtrain, Xtest)\n",
    "for i in range(5):\n",
    "    lgbm21_params['n_estimators'] = lgbm21_iter[i]\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **lgbm21_params)\n",
    "    callbacks = [lgb.log_evaluation(period=0)]\n",
    "    model.fit(Xtrain, ytrain, callbacks=callbacks, eval_metric = \"auc\")\n",
    "    lgbm21_model.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f5f4338c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:06:10.137173Z",
     "iopub.status.busy": "2024-10-31T09:06:10.136717Z",
     "iopub.status.idle": "2024-10-31T09:06:14.840125Z",
     "shell.execute_reply": "2024-10-31T09:06:14.838605Z"
    },
    "papermill": {
     "duration": 4.719252,
     "end_time": "2024-10-31T09:06:14.842776",
     "exception": false,
     "start_time": "2024-10-31T09:06:10.123524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC Score: 0.9582726406935467\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(ytest, lgbm_pred(lgbm21_model, Xtest))\n",
    "print(\"Test ROC AUC Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e861cf85",
   "metadata": {
    "papermill": {
     "duration": 0.011113,
     "end_time": "2024-10-31T09:06:14.865519",
     "exception": false,
     "start_time": "2024-10-31T09:06:14.854406",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. `lgbm31` Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "680a1329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:06:14.890942Z",
     "iopub.status.busy": "2024-10-31T09:06:14.890455Z",
     "iopub.status.idle": "2024-10-31T09:11:55.513936Z",
     "shell.execute_reply": "2024-10-31T09:11:55.512597Z"
    },
    "papermill": {
     "duration": 340.639965,
     "end_time": "2024-10-31T09:11:55.516991",
     "exception": false,
     "start_time": "2024-10-31T09:06:14.877026",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "lgbm31_model = []\n",
    "Xtest = test.copy()\n",
    "Xtrain = pd.read_csv(path + \"/merged.csv\")\n",
    "Xtrain, ytrain, Xtest, ytest = feature_engineering(Xtrain, Xtest)\n",
    "for i in range(5):\n",
    "    lgbm31_params['n_estimators'] = lgbm31_iter[i]\n",
    "    model = lgb.LGBMClassifier(random_state = random_state, **lgbm31_params)\n",
    "    callbacks = [lgb.log_evaluation(period=0)]\n",
    "    model.fit(Xtrain, ytrain, callbacks=callbacks, eval_metric = \"auc\")\n",
    "    lgbm31_model.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "37221ea5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:11:55.542154Z",
     "iopub.status.busy": "2024-10-31T09:11:55.541675Z",
     "iopub.status.idle": "2024-10-31T09:12:09.396572Z",
     "shell.execute_reply": "2024-10-31T09:12:09.395081Z"
    },
    "papermill": {
     "duration": 13.870568,
     "end_time": "2024-10-31T09:12:09.399288",
     "exception": false,
     "start_time": "2024-10-31T09:11:55.528720",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC AUC Score: 0.9571304615050887\n"
     ]
    }
   ],
   "source": [
    "score = roc_auc_score(ytest, lgbm_pred(lgbm31_model, Xtest))\n",
    "print(\"Test ROC AUC Score: \" + str(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccdcd22",
   "metadata": {
    "papermill": {
     "duration": 0.011715,
     "end_time": "2024-10-31T09:12:09.422446",
     "exception": false,
     "start_time": "2024-10-31T09:12:09.410731",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Save Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045a156a",
   "metadata": {},
   "source": [
    "The three trained models `1gbm11`, `lgbm21`, `lgbm31` are stored as they will be later aggregated by diverse methods in the effort to increase the score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a6ce4f88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-10-31T09:12:09.447676Z",
     "iopub.status.busy": "2024-10-31T09:12:09.447199Z",
     "iopub.status.idle": "2024-10-31T09:12:16.950334Z",
     "shell.execute_reply": "2024-10-31T09:12:16.949068Z"
    },
    "papermill": {
     "duration": 7.518955,
     "end_time": "2024-10-31T09:12:16.953198",
     "exception": false,
     "start_time": "2024-10-31T09:12:09.434243",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import joblib\n",
    "# all_models = [lgbm11_model, lgbm21_model, lgbm31_model]\n",
    "# models_name = [\"lgbm11\", \"lgbm21\", \"lgbm31\"]\n",
    "# for i in range(3):\n",
    "#     for j in range(5):\n",
    "#         name = models_name[i] + \"_\" + str(j) + \".pkl\"\n",
    "#         joblib.dump(all_models[i][j], name)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 9709193,
     "sourceId": 84894,
     "sourceType": "competition"
    },
    {
     "datasetId": 5982384,
     "sourceId": 9767803,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 204145199,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 609.140156,
   "end_time": "2024-10-31T09:12:17.990267",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-10-31T09:02:08.850111",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
